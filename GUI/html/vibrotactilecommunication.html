<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="theme-color" content="#222222">
    <title>Interaction Lab - Haptic Interaction</title>
    <link href="../css/bootstrap.css" rel="stylesheet">
    <link href="../css/modern-business.css" rel="stylesheet">
    <link href="../font-awesome/css/font-awesome.min.css" rel="stylesheet">
</head>
<body>
    <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand home" href="../../index.html"> </a>
            </div>

            <div class="collapse navbar-collapse navbar-ex1-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li class="dropdown"><a href="#" class="dropdown-toggle" data-toggle="dropdown">EXTERNAL LINKS <b class="caret"></b></a><ul class="dropdown-menu"><li><a href="https://wiki.inf.ufrgs.br/Computer_Graphics,_Image_Processing_and_Interaction">Lab Wiki</a></li><li><a href="http://www.inf.ufrgs.br/~vajoliveira/LabCloud/index.html">LabCloud</a></li><li><a href="https://vimeo.com/groups/cgufrgs/videos">Vimeo</a></li></ul></li>
                </ul>
            </div>
        </div>
    </nav>
    <div class="section">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <h1 class="page-header">Haptic Interaction</h1>
                    <ol class="breadcrumb">
                        <li><a href="../../index.html">Home</a>
                        </li>
                        <li class="active">Haptic Interaction</li>
                    </ol>
                </div>
            </div>

            <div class="row">

                <div class="col-md-4">
                    <video width="100%" height="100%" controls>
                        <source src="../../VIDEOS/haptics/VR2017.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-md-8">
                    <h3 style="margin-top:0;">Designing a Vibrotactile Head-mounted Display for Spatial Awareness in 3D Spaces
                    <br/><spam class="small">VR 2017 (to appear)</spam></h3>

                    <p><b>Authors:</b> de JESUS OLIVEIRA, V. A., BRAYDA, L., NEDEL, L., MACIEL, A.</p>
                    <p><b>Abstract:</b> Due to the perceptual characteristics of the head, vibrotactile Head-mounted Displays are built with low actuator density. Therefore, vibrotactile guidance is mostly assessed by pointing towards objects in the azimuthal plane. When it comes to multisensory interaction in 3D environments, it is also important to convey information about objects in the elevation plane. In this paper, we design and assess a haptic guidance technique for 3D environments. First, we explore the modulation of vibration frequency to indicate the position of objects in the elevation plane. Then, we assessed a vibrotactile HMD made to render the position of objects in a 3D space around the subject by varying both stimulus loci and vibration frequency. Results have shown that frequencies modulated with a quadratic growth function allowed a more accurate, precise, and faster target localization in an active head pointing task. The technique presented high usability and a strong learning effect for a haptic search across different scenarios in an immersive VR setup.</p>

                    [<a href="../../PAPERS/hapticpapers/VR2017.pdf">paper</a>]
                </div>

                <div class="col-md-12">
                    <h2 class="page-header"> </h2>
                </div>
            
                <div class="col-md-4">
                    <video width="100%" height="100%" controls>
                        <source src="../../VIDEOS/haptics/asia.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-md-8">
                    <h3 style="margin-top:0;">Tactile Treasure Map: Integrating Allocentric and Egocentric Information for Tactile Guidance
                    <br/><spam class="small">ASIAHAPTICS 2016</spam></h3>

                    <p><b>Authors:</b> MEMEO, M., de JESUS OLIVEIRA, V. A., NEDEL, L., MACIEL, A., BRAYDA, L.</p>
                    <p><b>Abstract:</b> With interactive maps a person can manage to find the way from one point to another, using an allocentric perspective (e.g. Google Maps), but also looking at a location as from the inside of the map with an egocentric perspective (e.g. Google Street View). Such experience cannot be performed with tactile maps, mostly explored from a top-view. To solve this, we built a system with two different but complementary devices. When coupled, they can provide both allocentric and egocentric spatial information to support the exploration of interactive tactile maps. To show the potential of the system, we built a blind treasure hunt.</p>

                    [<a href="../../PAPERS/hapticpapers/MemeoOliveira_TactileTreasureMap.pdf">paper</a>]
                </div>

                <div class="col-md-12">
                    <h2 class="page-header"> </h2>
                </div>

                <div class="col-md-4">
                    <img class="img-responsive" src="../images/task.png" alt="EUROHAPTICS" />
                </div>
                <div class="col-md-8">
                    <h3 style="margin-top:0;">Localized Magnification in Vibrotactile HMDs for Accurate Spatial Awareness
                    <br/><spam class="small">EUROHAPTICS 2016</spam></h3>

                    <p><b>Authors:</b> de JESUS OLIVEIRA, V. A., NEDEL, L., MACIEL, A., BRAYDA, L.</p>
                    <p><b>Abstract:</b> Actuator density is an important parameter in the design of vibrotactile displays. When it comes to obstacle detection or navigation tasks, a high number of tactors may provide more information, but not necessarily better performance. Depending on the body site and vibration parameters adopted, high density can make it harder to detect tactors in an array. In this paper, we explore the trade-off between actuator density and precision by comparing three kinds of directional cues. After performing a within-subject naive search task using a head-mounted vibrotactile display, we found that increasing the density of the array locally provides higher performance in detecting directional cues.</p>

                    [<a href="../../PAPERS/hapticpapers/Eurohaptics.pdf">paper</a>]
                </div>
                
                <div class="col-md-12">
                    <h2 class="page-header"> </h2>
                </div>

                <div class="col-md-4">
                    <img class="img-responsive" src="../images/regions.png" alt="HAPTICS" />
                </div>
                <div class="col-md-8">
                    <h3 style="margin-top:0;">Spatial Discrimination of Vibrotactile Stimuli Around the Head
                    <br/><spam class="small">Haptics Symposium 2016</spam></h3>

                    <p ><b>Authors:</b> de JESUS OLIVEIRA, V. A., NEDEL, L., MACIEL, A., BRAYDA, L.</p>
                    <p><b>Abstract:</b> Several studies evaluated vibrotactile stimuli on the head to aid orientation and communication. However, the acuity for vibration of the head's skin still needs to be explored. In this paper, we report the assessment of the spatial resolution on the head. We performed a 2AFC psychophysical experiment systematically varying the distance between pairs of stimuli in a standard-comparison approach. We took into consideration not only the perceptual thresholds but also the reaction times and subjective factors, like workload and vibration pleasantness. Results show that the region around the forehead is not only the most sensitive, with thresholds under 5mm, but it is also the region wherein the spatial discrimination was felt to be easier to perform. We also have found that it is possible to describe acuity on the head for vibrating stimulus as a function of skin type (hairy or glabrous) and of the distance of the stimulated loci from the head midline.</p>

                    [<a href="../../PAPERS/hapticpapers/Paper113_SpatialDiscrimination.pdf">paper</a>]
                </div>
                
                <div class="col-md-12">
                    <h2 class="page-header"> </h2>
                </div>

                <div class="col-md-4">
                    <video width="100%" height="100%" controls>
                        <source src="../../VIDEOS/haptics/Proactive.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-md-8">
                    <h3 style="margin-top:0;">Proactive Haptic Articulation for Intercommunication in Collaborative Virtual Environments
                    <br/><spam class="small">3DUI 2016</spam></h3>

                    <p><b>Authors:</b> de JESUS OLIVEIRA, V. A., NEDEL, L., MACIEL, A.</p>
                    <p><b>Abstract:</b> In this paper, we look upon elements present in speech articulation to introduce proactive haptic articulation as a novel approach for communication in Collaborative Virtual Environments. We defend the hypothesis that elements present in natural language, when added to the design of the vibrotactile vocabulary, should provide an expressive medium for intercommunication. Moreover, the ability to render tactile cues to a teammate should encourage users to extrapolate a given vocabulary while using it. We implemented a collaborative puzzle task to observe the use of such vocabulary. Results show that participants autonomously adapted it to attend their communication needs during the assembly.</p>

                    [<a href="../../PAPERS/hapticpapers/3DUI2016.pdf">paper</a>] [<a href="../images/publications/PaperVR.pdf">related poster (VR 2015)</a>] [<a href="../images/publications/VR2016Poster.png">related poster (VR 2016)</a>]
                </div>
                
                <div class="col-md-12">
                    <h2 class="page-header"> </h2>
                </div>

                <div class="col-md-4">
                    <video width="100%" height="100%" controls>
                        <source src="../../VIDEOS/haptics/BlindGuardian.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-md-8">
                    <h3 style="margin-top:0;">Blind Guardian: A Sonar-Based Solution for Avoiding Collisions with the Real World
                    <br/><spam class="small">SVR 2015</spam></h3>

                    <p><b>Authors:</b> Marina F. Rey, Inatan Hertzog, Nicolas Kagami and Luciana Nedel</p>
                    <p><b>Abstract:</b> Sightless navigation is an ever-present issue that affects a great part of the population. The affected include permanent or temporarily blind individuals, persons walking in the dark, and users of immersive virtual environments using real walking for navigation. This paper presents an alternative solution to this problem, which relies on a simple wearable device based on ultrasonic waves to detect obstacles and on vibrotactile feedback to warn the user of nearby obstacles. In the following pages, we describe the design and implementation of this apparatus, called the Blind Guardian. We conducted user tests with 29 subjects in a controlled environment. Results demonstrated the potential of Blind Guardian for future use in real life situations, as well as for immersive virtual reality applications based on the use of head-mounted displays.</p>

                    [<a href="../../PAPERS/hapticpapers/BlindGuardian.pdf">paper</a>]
                </div>
                
                <div class="col-md-12">
                    <h2 class="page-header"> </h2>
                </div>

                <div class="col-md-4">
                    <video width="100%" height="100%" controls>
                        <source src="../../VIDEOS/haptics/SVR2014.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-md-8">
                    <h3 style="margin-top:0;">Tactile Interface for Navigation in Underground Mines
                    <br/><spam class="small">SVR 2014</spam></h3>

                    <p><b>Authors:</b> de JESUS OLIVEIRA, V. A., MARQUES, E., PERONI, R. de L. and MACIEL, A.</p>
                    <p><b>Abstract:</b> This paper presents the design and evaluation of a tactile vocabulary to aid navigation in an underground mine. We studied different ways to construct tactile vocabularies and assessed several tactile icons for aid navigation. After trying a dozen stimuli families, we have selected tactons based on the users' ability to perceive and process them during navigation in virtual environments to design a more usable tactile interface. Then, we performed a user experiment in a virtual simulation of an emergency situation in an underground mine. The user study shows that the tactile feedback facilitated the execution of the task. Also, the perceptual adjustment of the tactile vocabulary increased its usability as well as the memorization of its signals.</p>

                    <p><img class="img-responsive" src="../images/prize_winner.png" alt="Best Paper" title="Best Paper Prize" style="display:inline"> <spam class="prizetxt">Best Application Paper Prize</spam></p>

                    [<a href="../../PAPERS/hapticpapers/SVR2014.pdf">paper</a>]
                </div>
                
                <div class="col-md-12">
                    <h2 class="page-header"> </h2>
                </div>

                <div class="col-md-4">
                    <video width="100%" height="100%" controls>
                        <source src="../../VIDEOS/haptics/eurohaptics2014_147.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-md-8">
                    <h3 style="margin-top:0;">Assessment of Tactile Languages as Navigation Aid in 3D Environments
                    <br/><spam class="small">EUROHAPTICS 2014</spam></h3>

                    <p><b>Authors:</b> de JESUS OLIVEIRA, V. A. and MACIEL, A.</p>
                    <p><b>Abstract:</b> In this paper we present the design and evaluate alternative tactile vocabularies to support navigation in 3D environments. We have focused on the tactile communication expressiveness by applying a prefixation approach in the construction of the tactile icons. We conducted user experiments to analyze the effects of both prefixation and the use of tactile sequences on the user's performance in a navigation task. Results show that, even if tactile sequences are more difficult to process during the navigation task, the prefixed patterns were easier to learn in all assessed vocabularies.</p>

                    [<a href="../../PAPERS/hapticpapers/PaperAssessment.pdf">paper</a>] [<a href="../images/publications/PaperAssessment.pdf">poster</a>] [<a href="../images/publications/Poster3DUI.pdf">related poster (3DUI 2014)</a>]
                </div>
                
                <div class="col-md-12">
                    <h2 class="page-header"> </h2>
                </div>

                <div class="col-md-4">
                    <video width="100%" height="100%" controls>
                        <source src="../../VIDEOS/haptics/eurohaptics2014_145.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-md-8">
                    <h3 style="margin-top:0;">Introducing the Modifier Tactile Pattern for Vibrotactile Communication
                    <br/><spam class="small">EUROHAPTICS 2014</spam></h3>

                    <p><b>Authors:</b> de JESUS OLIVEIRA, V. A. and MACIEL, A.</p>
                    <p><b>Abstract:</b> We introduce the concept of "Modifier Tactile Pattern" as a pattern that modifies the interpretation of other elements that compose a Tacton or an entire tactile message. This concept was inspired by the prefixation strategies of the Braille system. We also show how to design tactile languages applying the concept of Modifier by following method- ologies and approaches of Tacton design that already exist in literature. Then a modifier-based tactile language is designed and assessed in a user study.</p>

                    [<a href="../../PAPERS/hapticpapers/PaperModifier.pdf">paper</a>] [<a href="../images/publications/PaperModifier.pdf">poster</a>]
                </div>

                <div class="col-md-12">
                    <h2 class="page-header"> </h2>
                </div>

                <div class="col-md-4">
                    <video width="100%" height="100%" controls>
                        <source src="../../VIDEOS/haptics/SBGamesFinal.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-md-8">
                    <h3 style="margin-top:0;">Inclusive Games: A Multimodal Experience for Blind Players
                    <br/><spam class="small">SBGAMES 2011</spam></h3>

                    <p><b>Authors:</b> Jean Felipe Patikowski Cheiran, Luciana Nedel and Marcelo Pimenta</p>
                    <p><b>Abstract:</b> Electronic games have an important role in the human development so we can face the world of constantly changing technologies. Considering that the most of games is grounded in the interaction through visual elements and that the most of alternate games for blind is less attractive to non-blind people, we have developed a prototype of a 3D environment with dense sound experience and haptic feedback that would allow to blind and non-blind users orientate and move through it. Designing this environment like a game, we have employed blindfolded and non-blindfolded users to evaluate the major interaction issues in order to refine the software and make it mature to be used for the research with blind subjects.</p>

                    [<a href="../../PAPERS/hapticpapers/SBGamesFinal.pdf">paper</a>]
                </div>
                
            </div>
        </div>
    </div>
    <div class="container">
        <hr>
        <footer>
            <div class="row">
                <div class="col-lg-12">
                <a href="http://www.ufrgs.br/ufrgs/inicial" class="logo"><img src="../images/ufrgs.png" alt="logo da UFRGS" title="Universidade Federal do Rio Grande do Sul" height="50px"/></a>
                <a href="http://www.inf.ufrgs.br/" class="logo"><img src="../images/inf.png" alt="logo do INF" title="Instituto de Informática UFRGS"  height="50px"/></a>
                <a href="https://wiki.inf.ufrgs.br/Computer_Graphics,_Image_Processing_and_Interaction" class="logo"><img src="../images/logo.png" alt="logo do Laboratório de Computação Gráfica, Visualização e Interação" title="Laboratório de Computação Gráfica, Visualização e Interação"  height="50px"/></a>
                <p>Instituto de Informática - UFRGS<br/>
                    Caixa Postal 15064, CEP: 91501-970 Porto Alegre - RS - Brasil<br/>
                    Fone +55 (51) 3308-6168 / Fax +55 (51) 3308-7308</p>
                </div>
            </div>
        </footer>
    </div>

    <script src="../js/jquery-1.10.2.js"></script>
    <script src="../js/bootstrap.js"></script>
    <script src="../js/modern-business.js"></script>
    <noscript>
        <p>O JavaScript não está funcionando, você pode ter problemas ao utilizar esta página.</p>
    </noscript>
</body>
</html>
